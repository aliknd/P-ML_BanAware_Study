{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fc5d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa87750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"25.csv\")\n",
    "\n",
    "# Separate data into different dataframes based on data types\n",
    "spo2_data = data[data['data_type'] == 'spo2'].copy()\n",
    "heart_rate_data = data[data['data_type'] == 'hr'].copy()\n",
    "steps_data = data[data['data_type'] == 'steps'].copy()\n",
    "hrv_data = data[data['data_type'] == 'hrv'].copy()\n",
    "br_data = data[data['data_type'] == 'br'].copy()\n",
    "sleep_data = data[data['data_type'] == 'sleep'].copy()\n",
    "\n",
    "# Convert timestamps to datetime format for each dataframe\n",
    "spo2_data['time'] = pd.to_datetime(spo2_data['time'])\n",
    "heart_rate_data['time'] = pd.to_datetime(heart_rate_data['time'])\n",
    "steps_data['time'] = pd.to_datetime(steps_data['time'])\n",
    "hrv_data['time'] = pd.to_datetime(hrv_data['time'])\n",
    "br_data['time'] = pd.to_datetime(br_data['time'])\n",
    "sleep_data['time'] = pd.to_datetime(sleep_data['time'])\n",
    "\n",
    "# Sort dataframes based on time and their respective formats\n",
    "spo2_data.sort_values(by='time', inplace=True)\n",
    "heart_rate_data.sort_values(by='time', inplace=True)\n",
    "steps_data.sort_values(by='time', inplace=True)\n",
    "hrv_data.sort_values(by='time', inplace=True)\n",
    "br_data.sort_values(by='time', inplace=True)\n",
    "sleep_data.sort_values(by='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c06502",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_data=heart_rate_data[['value', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3062db4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2024-03-08 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>2024-03-08 00:01:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>2024-03-08 00:02:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65</td>\n",
       "      <td>2024-03-08 00:03:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65</td>\n",
       "      <td>2024-03-08 00:04:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40503</th>\n",
       "      <td>73</td>\n",
       "      <td>2024-04-05 23:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40504</th>\n",
       "      <td>73</td>\n",
       "      <td>2024-04-05 23:56:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40505</th>\n",
       "      <td>74</td>\n",
       "      <td>2024-04-05 23:57:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40506</th>\n",
       "      <td>74</td>\n",
       "      <td>2024-04-05 23:58:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40507</th>\n",
       "      <td>71</td>\n",
       "      <td>2024-04-05 23:59:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      value                      time\n",
       "1        64 2024-03-08 00:00:00+00:00\n",
       "3        62 2024-03-08 00:01:00+00:00\n",
       "4        63 2024-03-08 00:02:00+00:00\n",
       "5        65 2024-03-08 00:03:00+00:00\n",
       "6        65 2024-03-08 00:04:00+00:00\n",
       "...     ...                       ...\n",
       "40503    73 2024-04-05 23:55:00+00:00\n",
       "40504    73 2024-04-05 23:56:00+00:00\n",
       "40505    74 2024-04-05 23:57:00+00:00\n",
       "40506    74 2024-04-05 23:58:00+00:00\n",
       "40507    71 2024-04-05 23:59:00+00:00\n",
       "\n",
       "[28317 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_rate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1f459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_data=steps_data[['value', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293fadaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15</td>\n",
       "      <td>2024-03-08 01:11:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-03-08 01:13:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>25</td>\n",
       "      <td>2024-03-08 01:49:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-03-08 02:17:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-03-08 02:29:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40402</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-04-05 22:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40412</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-04-05 22:28:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>13</td>\n",
       "      <td>2024-04-05 22:42:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-05 23:03:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-04-05 23:06:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      value                      time\n",
       "46       15 2024-03-08 01:11:00+00:00\n",
       "48        8 2024-03-08 01:13:00+00:00\n",
       "85       25 2024-03-08 01:49:00+00:00\n",
       "116       9 2024-03-08 02:17:00+00:00\n",
       "130       8 2024-03-08 02:29:00+00:00\n",
       "...     ...                       ...\n",
       "40402     7 2024-04-05 22:18:00+00:00\n",
       "40412     7 2024-04-05 22:28:00+00:00\n",
       "40428    13 2024-04-05 22:42:00+00:00\n",
       "40450     4 2024-04-05 23:03:00+00:00\n",
       "40453     7 2024-04-05 23:06:00+00:00\n",
       "\n",
       "[6250 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ee195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Craving Features Data:\n",
      "            timestamp                                   heart_rate_means  \\\n",
      "0 2024-03-08 21:00:35  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1 2024-03-09 21:01:05  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2 2024-03-11 21:03:19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3 2024-03-21 15:20:07  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4 2024-03-22 10:00:44  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                         steps_means  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "Non-Craving Features Data:\n",
      "            timestamp                                   heart_rate_means  \\\n",
      "0 2024-03-08 10:41:54  [-0.09184025046275009, 0.2323018099940171, 0.3...   \n",
      "1 2024-03-08 13:00:44  [0.6393592140252059, -0.21638821778266962, -0....   \n",
      "2 2024-03-08 17:03:27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3 2024-03-09 10:25:48  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4 2024-03-09 13:00:30  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                         steps_means  \n",
      "0  [-0.4009044819248994, -0.4009044819248994, -0....  \n",
      "1  [-0.15966613222220438, -0.7693004552524393, -0...  \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load craving and non-craving data\n",
    "craving_data = pd.read_csv('ID25_Crave.csv')\n",
    "non_craving_data = pd.read_csv('ID25_None.csv')\n",
    "\n",
    "# Filter rows with 'Carrot' in the substance_fruit_label column\n",
    "craving_data = craving_data[craving_data['substance_fruit_label'] == 'Carrot']\n",
    "\n",
    "# Convert timestamps to ensure they are timezone-naive\n",
    "craving_data['hawaii_createdat_time'] = pd.to_datetime(craving_data['hawaii_createdat_time']).dt.tz_localize(None)\n",
    "non_craving_data['hawaii_createdat_time'] = pd.to_datetime(non_craving_data['hawaii_createdat_time']).dt.tz_localize(None)\n",
    "\n",
    "# Ensure heart rate and steps data use the same timezone-naive datetime index\n",
    "heart_rate_data['time'] = pd.to_datetime(heart_rate_data['time']).dt.tz_localize(None)\n",
    "steps_data['time'] = pd.to_datetime(steps_data['time']).dt.tz_localize(None)\n",
    "\n",
    "heart_rate_data.set_index('time', inplace=True)\n",
    "steps_data.set_index('time', inplace=True)\n",
    "\n",
    "# Convert the 'value' column to numeric, coercing errors\n",
    "heart_rate_data['value'] = pd.to_numeric(heart_rate_data['value'], errors='coerce')\n",
    "steps_data['value'] = pd.to_numeric(steps_data['value'], errors='coerce')\n",
    "\n",
    "# Remove duplicate timestamps\n",
    "heart_rate_data = heart_rate_data[~heart_rate_data.index.duplicated(keep='first')]\n",
    "steps_data = steps_data[~steps_data.index.duplicated(keep='first')]\n",
    "\n",
    "# Reindex and forward fill to handle missing data\n",
    "heart_rate_data = heart_rate_data.reindex(pd.date_range(start=heart_rate_data.index.min(), end=heart_rate_data.index.max(), freq='min'), method='ffill')\n",
    "steps_data = steps_data.reindex(pd.date_range(start=steps_data.index.min(), end=steps_data.index.max(), freq='min'), method='ffill').fillna(0)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def process_label_data(label_data, heart_rate_data, steps_data, scaler):\n",
    "    results = []\n",
    "    for _, row in label_data.iterrows():\n",
    "        timestamp = row['hawaii_createdat_time']\n",
    "        lower_bound = timestamp - pd.Timedelta(hours=1)\n",
    "        upper_bound = timestamp + pd.Timedelta(hours=1)\n",
    "\n",
    "        # Extract data within the window\n",
    "        hr_window = heart_rate_data.loc[lower_bound:upper_bound]\n",
    "        steps_window = steps_data.loc[lower_bound:upper_bound]\n",
    "\n",
    "        # Resample and calculate mean every 4 minutes to get 30 points\n",
    "        hr_means = hr_window.resample('4min').mean().iloc[:30]  # Ensure 30 data points\n",
    "        steps_means = steps_window.resample('4min').mean().iloc[:30]\n",
    "\n",
    "        if len(hr_means) == 30 and len(steps_means) == 30:\n",
    "            # Standardize the means\n",
    "            hr_scaled = scaler.fit_transform(hr_means.values.reshape(-1, 1))\n",
    "            steps_scaled = scaler.fit_transform(steps_means.values.reshape(-1, 1))\n",
    "\n",
    "            results.append({\n",
    "                'timestamp': timestamp,\n",
    "                'heart_rate_means': hr_scaled.flatten().tolist(),\n",
    "                'steps_means': steps_scaled.flatten().tolist()\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process craving and non-craving labels\n",
    "craving_features = process_label_data(craving_data, heart_rate_data, steps_data, scaler)\n",
    "non_craving_features = process_label_data(non_craving_data, heart_rate_data, steps_data, scaler)\n",
    "\n",
    "# Output results\n",
    "print(\"Craving Features Data:\")\n",
    "print(craving_features.head())\n",
    "print(\"Non-Craving Features Data:\")\n",
    "print(non_craving_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc085be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Craving Features Data: (5, 3)\n",
      "Shape of Non-Craving Features Data: (91, 3)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the craving features data\n",
    "print(\"Shape of Craving Features Data:\", craving_features.shape)\n",
    "\n",
    "# Print the shape of the non-craving features data\n",
    "print(\"Shape of Non-Craving Features Data:\", non_craving_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdfafd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp                                   heart_rate_means  \\\n",
      "0  2024-03-08 10:41:54  [-0.09184025046275009, 0.2323018099940171, 0.3...   \n",
      "1  2024-03-08 13:00:44  [0.6393592140252059, -0.21638821778266962, -0....   \n",
      "2  2024-03-08 17:03:27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  2024-03-08 21:00:35  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  2024-03-09 10:25:48  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "..                 ...                                                ...   \n",
      "91 2024-04-04 13:14:39  [-0.7126238512538401, -0.3477993540249117, -0....   \n",
      "92 2024-04-04 21:00:13  [-1.1404840042919875, -1.325164652714269, -1.4...   \n",
      "93 2024-04-05 09:16:50  [-1.3279360019674473, -2.0010052538412895, -1....   \n",
      "94 2024-04-05 13:13:37  [-1.5838886684145206, -1.6526537336134144, -1....   \n",
      "95 2024-04-05 21:00:17  [3.3461584365958, 1.806781013280667, 0.8311192...   \n",
      "\n",
      "                                          steps_means      state  state_val  \n",
      "0   [-0.4009044819248994, -0.4009044819248994, -0....  non_crave          0  \n",
      "1   [-0.15966613222220438, -0.7693004552524393, -0...  non_crave          0  \n",
      "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  non_crave          0  \n",
      "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      crave          1  \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  non_crave          0  \n",
      "..                                                ...        ...        ...  \n",
      "91  [-0.42641705014606135, -0.42641705014606135, -...  non_crave          0  \n",
      "92  [-0.9812135230802389, -1.1728924438680064, -1....  non_crave          0  \n",
      "93  [-0.1212633182409296, -0.1212633182409296, -0....  non_crave          0  \n",
      "94  [-1.1995551280129997, -1.1995551280129997, -1....  non_crave          0  \n",
      "95  [3.570853548450312, -0.5930392818981082, -0.59...  non_crave          0  \n",
      "\n",
      "[96 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adding label columns\n",
    "craving_features['state'] = 'crave'\n",
    "craving_features['state_val'] = 1\n",
    "\n",
    "non_craving_features['state'] = 'non_crave'\n",
    "non_craving_features['state_val'] = 0\n",
    "\n",
    "# Combining the dataframes\n",
    "combined_data = pd.concat([craving_features, non_craving_features])\n",
    "\n",
    "# Converting timestamps to datetime and sorting\n",
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "combined_data_sorted = combined_data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "# This combined_data_sorted is now ready for use in your neural network model\n",
    "print(combined_data_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81aa308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load pretrained models\n",
    "encoder_hr = tf.keras.models.load_model('heart_rate_encoder')\n",
    "encoder_steps = tf.keras.models.load_model('steps_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63d33482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to generate embeddings using the loaded models\n",
    "def generate_embeddings(hr_data, steps_data, encoder_hr, encoder_steps):\n",
    "    # Convert lists to numpy arrays and ensure they are in the correct shape\n",
    "    hr_data = np.array(hr_data.tolist())\n",
    "    steps_data = np.array(steps_data.tolist())\n",
    "\n",
    "    # Reshape data if required by the model, assuming the model expects shape (samples, features)\n",
    "    if hr_data.ndim == 1:\n",
    "        hr_data = hr_data.reshape(-1, 1)\n",
    "    if steps_data.ndim == 1:\n",
    "        steps_data = steps_data.reshape(-1, 1)\n",
    "\n",
    "    # Generate embeddings\n",
    "    hr_embeddings = encoder_hr.predict(hr_data)\n",
    "    steps_embeddings = encoder_steps.predict(steps_data)\n",
    "\n",
    "    return hr_embeddings, steps_embeddings\n",
    "\n",
    "# Use the function with your data\n",
    "hr_embeddings, steps_embeddings = generate_embeddings(\n",
    "    combined_data_sorted['heart_rate_means'],\n",
    "    combined_data_sorted['steps_means'],\n",
    "    encoder_hr,\n",
    "    encoder_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290ffada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 3s 119ms/step - loss: 2.6216 - accuracy: 0.8676 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2546 - val_accuracy: 0.7500 - val_precision: 0.3333 - val_recall: 1.0000\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7178 - accuracy: 0.8235 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1815 - val_accuracy: 0.7500 - val_precision: 0.3333 - val_recall: 1.0000\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0999 - accuracy: 0.7647 - precision: 0.1250 - recall: 0.5000 - val_loss: 2.1147 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9782 - accuracy: 0.8971 - precision: 0.2857 - recall: 0.5000 - val_loss: 2.0545 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2673 - accuracy: 0.8824 - precision: 0.1667 - recall: 0.2500 - val_loss: 1.9995 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8699 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.9505 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7793 - accuracy: 0.8088 - precision: 0.1538 - recall: 0.5000 - val_loss: 1.9068 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7769 - accuracy: 0.8088 - precision: 0.1538 - recall: 0.5000 - val_loss: 1.8677 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7453 - accuracy: 0.8529 - precision: 0.2000 - recall: 0.5000 - val_loss: 1.8299 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8212 - accuracy: 0.7941 - precision: 0.1429 - recall: 0.5000 - val_loss: 1.7939 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1794 - accuracy: 0.7500 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7613 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6514 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.7313 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7187 - accuracy: 0.8529 - precision: 0.2000 - recall: 0.5000 - val_loss: 1.7031 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5805 - accuracy: 0.8382 - precision: 0.1818 - recall: 0.5000 - val_loss: 1.6759 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5002 - accuracy: 0.7941 - precision: 0.1875 - recall: 0.7500 - val_loss: 1.6506 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6297 - accuracy: 0.8971 - precision: 0.3333 - recall: 0.7500 - val_loss: 1.6264 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5897 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.6052 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5640 - accuracy: 0.8529 - precision: 0.2500 - recall: 0.7500 - val_loss: 1.5848 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5679 - accuracy: 0.8088 - precision: 0.1538 - recall: 0.5000 - val_loss: 1.5665 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5702 - accuracy: 0.8529 - precision: 0.2500 - recall: 0.7500 - val_loss: 1.5495 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4989 - accuracy: 0.8382 - precision: 0.1818 - recall: 0.5000 - val_loss: 1.5343 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6260 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.5199 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3836 - accuracy: 0.7353 - precision: 0.1500 - recall: 0.7500 - val_loss: 1.5066 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5375 - accuracy: 0.7794 - precision: 0.0769 - recall: 0.2500 - val_loss: 1.4936 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5714 - accuracy: 0.8088 - precision: 0.0909 - recall: 0.2500 - val_loss: 1.4822 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3095 - accuracy: 0.8676 - precision: 0.2727 - recall: 0.7500 - val_loss: 1.4699 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3932 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.4584 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2440 - accuracy: 0.8235 - precision: 0.2143 - recall: 0.7500 - val_loss: 1.4469 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4123 - accuracy: 0.8529 - precision: 0.1250 - recall: 0.2500 - val_loss: 1.4360 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4668 - accuracy: 0.7794 - precision: 0.0769 - recall: 0.2500 - val_loss: 1.4255 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2595 - accuracy: 0.8382 - precision: 0.1818 - recall: 0.5000 - val_loss: 1.4136 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4360 - accuracy: 0.8088 - precision: 0.1538 - recall: 0.5000 - val_loss: 1.4015 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3048 - accuracy: 0.7647 - precision: 0.1667 - recall: 0.7500 - val_loss: 1.3887 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3572 - accuracy: 0.8529 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3783 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2664 - accuracy: 0.8382 - precision: 0.1818 - recall: 0.5000 - val_loss: 1.3697 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3208 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.3595 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0885 - accuracy: 0.8824 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2571 - accuracy: 0.8676 - precision: 0.3077 - recall: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3131 - accuracy: 0.8235 - precision: 0.1667 - recall: 0.5000 - val_loss: 1.3279 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2680 - accuracy: 0.7794 - precision: 0.1765 - recall: 0.7500 - val_loss: 1.3195 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1774 - accuracy: 0.8088 - precision: 0.2000 - recall: 0.7500 - val_loss: 1.3109 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2097 - accuracy: 0.8676 - precision: 0.2727 - recall: 0.7500 - val_loss: 1.3021 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1957 - accuracy: 0.8382 - precision: 0.2308 - recall: 0.7500 - val_loss: 1.2963 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2510 - accuracy: 0.8088 - precision: 0.2000 - recall: 0.7500 - val_loss: 1.2887 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2805 - accuracy: 0.7500 - precision: 0.1176 - recall: 0.5000 - val_loss: 1.2824 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0813 - accuracy: 0.8676 - precision: 0.2727 - recall: 0.7500 - val_loss: 1.2758 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3000 - accuracy: 0.8382 - precision: 0.1111 - recall: 0.2500 - val_loss: 1.2685 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9752 - accuracy: 0.8235 - precision: 0.2143 - recall: 0.7500 - val_loss: 1.2539 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1857 - accuracy: 0.8235 - precision: 0.2143 - recall: 0.7500 - val_loss: 1.2414 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1363 - accuracy: 0.8235 - precision: 0.2143 - recall: 0.7500 - val_loss: 1.2298 - val_accuracy: 0.6250 - val_precision: 0.2500 - val_recall: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "\n",
      "Training Set Evaluation:\n",
      "Threshold: 0.00, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.01, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.02, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.03, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.04, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.05, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.06, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.07, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.08, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.09, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.10, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.11, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.12, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.13, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.14, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.15, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.16, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.17, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.18, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.19, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.20, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.21, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.22, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.23, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.24, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.25, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.26, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.27, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.28, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.29, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.30, Sensitivity: 1.00, Specificity: 0.00, Accuracy: 0.07\n",
      "Threshold: 0.31, Sensitivity: 1.00, Specificity: 0.03, Accuracy: 0.09\n",
      "Threshold: 0.32, Sensitivity: 1.00, Specificity: 0.06, Accuracy: 0.12\n",
      "Threshold: 0.33, Sensitivity: 1.00, Specificity: 0.15, Accuracy: 0.21\n",
      "Threshold: 0.34, Sensitivity: 1.00, Specificity: 0.23, Accuracy: 0.28\n",
      "Threshold: 0.35, Sensitivity: 1.00, Specificity: 0.27, Accuracy: 0.32\n",
      "Threshold: 0.36, Sensitivity: 1.00, Specificity: 0.31, Accuracy: 0.36\n",
      "Threshold: 0.37, Sensitivity: 1.00, Specificity: 0.42, Accuracy: 0.46\n",
      "Threshold: 0.38, Sensitivity: 1.00, Specificity: 0.48, Accuracy: 0.51\n",
      "Threshold: 0.39, Sensitivity: 1.00, Specificity: 0.54, Accuracy: 0.57\n",
      "Threshold: 0.40, Sensitivity: 1.00, Specificity: 0.58, Accuracy: 0.61\n",
      "Threshold: 0.41, Sensitivity: 1.00, Specificity: 0.63, Accuracy: 0.66\n",
      "Threshold: 0.42, Sensitivity: 1.00, Specificity: 0.66, Accuracy: 0.68\n",
      "Threshold: 0.43, Sensitivity: 1.00, Specificity: 0.69, Accuracy: 0.71\n",
      "Threshold: 0.44, Sensitivity: 1.00, Specificity: 0.69, Accuracy: 0.71\n",
      "Threshold: 0.45, Sensitivity: 1.00, Specificity: 0.72, Accuracy: 0.74\n",
      "Threshold: 0.46, Sensitivity: 1.00, Specificity: 0.75, Accuracy: 0.76\n",
      "Threshold: 0.47, Sensitivity: 1.00, Specificity: 0.76, Accuracy: 0.78\n",
      "Threshold: 0.48, Sensitivity: 1.00, Specificity: 0.76, Accuracy: 0.78\n",
      "Threshold: 0.49, Sensitivity: 1.00, Specificity: 0.77, Accuracy: 0.79\n",
      "Threshold: 0.50, Sensitivity: 1.00, Specificity: 0.77, Accuracy: 0.79\n",
      "Threshold: 0.51, Sensitivity: 1.00, Specificity: 0.77, Accuracy: 0.79\n",
      "Threshold: 0.52, Sensitivity: 1.00, Specificity: 0.79, Accuracy: 0.80\n",
      "Threshold: 0.53, Sensitivity: 1.00, Specificity: 0.80, Accuracy: 0.82\n",
      "Threshold: 0.54, Sensitivity: 1.00, Specificity: 0.80, Accuracy: 0.82\n",
      "Threshold: 0.55, Sensitivity: 1.00, Specificity: 0.80, Accuracy: 0.82\n",
      "Threshold: 0.56, Sensitivity: 1.00, Specificity: 0.80, Accuracy: 0.82\n",
      "Threshold: 0.57, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.58, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.59, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.60, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.61, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.62, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.63, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.64, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.65, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.66, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.67, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.68, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.69, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.70, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.71, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.72, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.73, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.74, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.75, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.76, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.77, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.78, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.79, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.80, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.81, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.82, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.83, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.84, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.85, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.86, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.87, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.88, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.89, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.90, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.91, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.92, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.93, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.94, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.95, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.96, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.97, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.98, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 0.99, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "Threshold: 1.00, Sensitivity: 0.00, Specificity: 1.00, Accuracy: 0.93\n",
      "\n",
      "Best Threshold from Training Set: 0.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "Test Set Evaluation at Best Threshold (0.39):\n",
      "Sensitivity: nan\n",
      "Specificity: 0.40\n",
      "Accuracy: 0.40\n",
      "Threshold: 0.00, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.01, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.02, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.03, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.04, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.05, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.06, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.07, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.08, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.09, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.10, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.11, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.12, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.13, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.14, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.15, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.16, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.17, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.18, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.19, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.20, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.21, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.22, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.23, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.24, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.25, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.26, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.27, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.28, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.29, Sensitivity: nan, Specificity: 0.00, Accuracy: 0.00\n",
      "Threshold: 0.30, Sensitivity: nan, Specificity: 0.05, Accuracy: 0.05\n",
      "Threshold: 0.31, Sensitivity: nan, Specificity: 0.05, Accuracy: 0.05\n",
      "Threshold: 0.32, Sensitivity: nan, Specificity: 0.10, Accuracy: 0.10\n",
      "Threshold: 0.33, Sensitivity: nan, Specificity: 0.15, Accuracy: 0.15\n",
      "Threshold: 0.34, Sensitivity: nan, Specificity: 0.15, Accuracy: 0.15\n",
      "Threshold: 0.35, Sensitivity: nan, Specificity: 0.30, Accuracy: 0.30\n",
      "Threshold: 0.36, Sensitivity: nan, Specificity: 0.35, Accuracy: 0.35\n",
      "Threshold: 0.37, Sensitivity: nan, Specificity: 0.35, Accuracy: 0.35\n",
      "Threshold: 0.38, Sensitivity: nan, Specificity: 0.40, Accuracy: 0.40\n",
      "Threshold: 0.39, Sensitivity: nan, Specificity: 0.40, Accuracy: 0.40\n",
      "Threshold: 0.40, Sensitivity: nan, Specificity: 0.45, Accuracy: 0.45\n",
      "Threshold: 0.41, Sensitivity: nan, Specificity: 0.55, Accuracy: 0.55\n",
      "Threshold: 0.42, Sensitivity: nan, Specificity: 0.65, Accuracy: 0.65\n",
      "Threshold: 0.43, Sensitivity: nan, Specificity: 0.65, Accuracy: 0.65\n",
      "Threshold: 0.44, Sensitivity: nan, Specificity: 0.65, Accuracy: 0.65\n",
      "Threshold: 0.45, Sensitivity: nan, Specificity: 0.70, Accuracy: 0.70\n",
      "Threshold: 0.46, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.47, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.48, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.49, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.50, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.51, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.52, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.53, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.54, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.55, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n",
      "Threshold: 0.56, Sensitivity: nan, Specificity: 0.75, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:90: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall_test = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_20668\\682625456.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = tp / (tp + fn)  # Sensitivity\n",
      "C:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 104\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m    103\u001b[0m     predicted_classes \u001b[38;5;241m=\u001b[39m (probabilities_test \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m     tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, predicted_classes)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    105\u001b[0m     recall \u001b[38;5;241m=\u001b[39m tp \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m fn)  \u001b[38;5;66;03m# Sensitivity\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     specificity \u001b[38;5;241m=\u001b[39m tn \u001b[38;5;241m/\u001b[39m (tn \u001b[38;5;241m+\u001b[39m fp)  \u001b[38;5;66;03m# Specificity\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Combine the heart rate and steps embeddings\n",
    "combined_embeddings = np.concatenate([hr_embeddings, steps_embeddings], axis=1)\n",
    "\n",
    "# Labels from your existing DataFrame\n",
    "labels = combined_data_sorted['state_val'].values\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model with regularization and batch normalization\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate thresholds on training set\n",
    "probabilities_train = model.predict(X_train)\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Store training results\n",
    "training_results = []\n",
    "\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "for threshold in thresholds:\n",
    "    predicted_classes = (probabilities_train > threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, predicted_classes).ravel()\n",
    "    recall = tp / (tp + fn)  # Sensitivity\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    training_results.append((threshold, recall, specificity, accuracy))\n",
    "    print(f\"Threshold: {threshold:.2f}, Sensitivity: {recall:.2f}, Specificity: {specificity:.2f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Convert training results to DataFrame for easy viewing\n",
    "training_results_df = pd.DataFrame(training_results, columns=['Threshold', 'Sensitivity', 'Specificity', 'Accuracy'])\n",
    "\n",
    "# Select best threshold based on a specific criterion\n",
    "# Here, we select the threshold with the highest sensitivity while keeping specificity above 0.5\n",
    "best_threshold_row = training_results_df[(training_results_df['Sensitivity'] > 0.9) & (training_results_df['Specificity'] > 0.5)]\n",
    "if not best_threshold_row.empty:\n",
    "    best_threshold = best_threshold_row.iloc[0]['Threshold']\n",
    "else:\n",
    "    best_threshold = 0.5  # Default threshold if criteria is not met\n",
    "\n",
    "print(f\"\\nBest Threshold from Training Set: {best_threshold}\")\n",
    "\n",
    "# Evaluate the best threshold on the test set\n",
    "probabilities_test = model.predict(X_test)\n",
    "predicted_classes_test = (probabilities_test > best_threshold).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "recall_test = tp / (tp + fn)  # Sensitivity\n",
    "specificity_test = tn / (tn + fp)  # Specificity\n",
    "accuracy_test = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(f\"\\nTest Set Evaluation at Best Threshold ({best_threshold}):\")\n",
    "print(f\"Sensitivity: {recall_test:.2f}\")\n",
    "print(f\"Specificity: {specificity_test:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_test:.2f}\")\n",
    "\n",
    "# Store test results\n",
    "test_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predicted_classes = (probabilities_test > threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predicted_classes).ravel()\n",
    "    recall = tp / (tp + fn)  # Sensitivity\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    test_results.append((threshold, recall, specificity, accuracy))\n",
    "    print(f\"Threshold: {threshold:.2f}, Sensitivity: {recall:.2f}, Specificity: {specificity:.2f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Convert test results to DataFrame for easy viewing\n",
    "test_results_df = pd.DataFrame(test_results, columns=['Threshold', 'Sensitivity', 'Specificity', 'Accuracy'])\n",
    "\n",
    "# Find the threshold where specificity is around 0.9 and sensitivity is around 0.5\n",
    "desired_specificity = 0.9\n",
    "desired_sensitivity_range = (0.4, 0.6)  # Considering sensitivity around 0.5\n",
    "\n",
    "filtered_results = test_results_df[\n",
    "    (test_results_df['Specificity'] >= desired_specificity) & \n",
    "    (test_results_df['Sensitivity'] >= desired_sensitivity_range[0]) & \n",
    "    (test_results_df['Sensitivity'] <= desired_sensitivity_range[1])\n",
    "]\n",
    "\n",
    "# Print the filtered results\n",
    "print(\"\\nFiltered Thresholds with Specificity >= 0.9 and Sensitivity ~ 0.5:\")\n",
    "print(filtered_results)\n",
    "\n",
    "# Plot the results for better visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_results_df['Threshold'], test_results_df['Sensitivity'], label='Sensitivity')\n",
    "plt.plot(test_results_df['Threshold'], test_results_df['Specificity'], label='Specificity')\n",
    "plt.plot(test_results_df['Threshold'], test_results_df['Accuracy'], label='Accuracy')\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='Desired Specificity (0.9)')\n",
    "plt.axhline(y=0.5, color='g', linestyle='--', label='Desired Sensitivity (0.5)')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Sensitivity, Specificity, and Accuracy vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold: 0.48, Sensitivity: 0.58, Specificity: 0.78, Accuracy: 0.67\n",
    "Threshold: 0.48, Sensitivity: 0.75, Specificity: 1.00, Accuracy: 0.83"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
